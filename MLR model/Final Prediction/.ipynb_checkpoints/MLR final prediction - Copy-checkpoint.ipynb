{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.dpi']= 120\n",
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameters\n",
    "\n",
    "input_size = 7\n",
    "output_size = 6\n",
    "\n",
    "\n",
    "seq_len = 3\n",
    "learning_rate = 0.0080409\n",
    "num_epochs = 100\n",
    "dropout = 0\n",
    "\n",
    "seed = 7123515\n",
    "load_model = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data importing\n",
    "df = pd.read_excel('ALL VAR cleaned.xlsx')\n",
    "df.Date = pd.to_datetime(df.Date, format = '%m/%d/%Y')\n",
    "df = df.set_index('Date')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#data scaling\n",
    "df_scaled = (df - df.mean())/ df.std()\n",
    "df_scaled.head()\n",
    "\n",
    "#storing mean and std\n",
    "df_np_mean = df.mean().to_numpy()\n",
    "df_np_std = df.std().to_numpy()\n",
    "\n",
    "#dropping date column\n",
    "df_scaled.reset_index(inplace = True)\n",
    "df_scaled = df_scaled.drop('Date', 1)\n",
    "df_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sequences(sequences, n_steps):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequences)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps\n",
    "        # check if we are beyond the dataset\n",
    "        if end_ix+1 >= len(sequences): break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequences[i:end_ix, 0:7], sequences[end_ix+1, 7:13]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return X, y\n",
    "\n",
    "array = df_scaled.iloc[:, :].values\n",
    "print ('shape of the datset array: {}'.format(array.shape))\n",
    "X, y = split_sequences(array, seq_len)\n",
    "X_array = np.array(X, dtype = np.float32)\n",
    "y_array = np.array(y)\n",
    "print ('sequenced X array shape: {}'.format(X_array.shape))\n",
    "print ('sequenced y array shape: {}'.format(y_array.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output mask preparation\n",
    "\n",
    "df_mask = pd.read_excel('COMBINED CAMS MASK.xlsx')\n",
    "#print(df_mask.head())\n",
    "\n",
    "mask_array = df_mask.iloc[:, :].values\n",
    "#print(mask_array.shape)\n",
    "\n",
    "#sequencing\n",
    "def mask_sequence(sequence, n_steps):\n",
    "    y = list()\n",
    "    for i in range(len(sequence)):\n",
    "        # find the end of this pattern\n",
    "        end_iy = i + n_steps\n",
    "        # check if we are beyond the dataset\n",
    "        if end_iy+1 >= len(sequence): break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_y = sequence[end_iy+1, 0:6]\n",
    "        y.append(seq_y)\n",
    "    return y\n",
    "\n",
    "mask_list = mask_sequence(mask_array, seq_len)\n",
    "mask_array = np.array(mask_list)\n",
    "print(mask_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making dataset and subsets\n",
    "\n",
    "class AirMeteoroDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.len = X_array.shape[0]\n",
    "        self.X_data = torch.from_numpy(X_array)\n",
    "        self.y_data = torch.from_numpy(y_array)\n",
    "        self.y_mask = torch.from_numpy(mask_array)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index], self.y_data[index], self.y_mask[index], index\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "dataset = AirMeteoroDataset()\n",
    "\n",
    "\n",
    "#dataset_random_split\n",
    "train_size = round(len(X_array) * 0.7)\n",
    "val_size = round((len(X_array) - train_size)/2)\n",
    "test_size = len(X_array) - train_size - val_size\n",
    "train_set, val_set, test_set = torch.utils.data.random_split(dataset,[train_size, val_size, test_size], generator = torch.Generator().manual_seed(seed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge train_val\n",
    "\n",
    "trainval_sets= []\n",
    "trainval_sets.append(train_set)\n",
    "trainval_sets.append(val_set)\n",
    "train_val_set = torch.utils.data.ConcatDataset(trainval_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, \n",
    "                 input_size, \n",
    "                 output_size, \n",
    "                 seq_len, \n",
    "                 dropout):\n",
    "        super(Model, self).__init__()\n",
    "        self.input_size = input_size*seq_len\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        self.dropout = nn.Dropout(p = dropout)\n",
    "        \n",
    "        self.linear = nn.Linear(self.input_size, self.output_size)\n",
    "\n",
    "    def forward(self, X):\n",
    "        \n",
    "        out = self.linear(self.dropout(X))\n",
    "        \n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class modsmoothl1(nn.SmoothL1Loss):\n",
    "    def __init__(self, size_average=None, reduce=None, reduction = 'none'):\n",
    "        super(modsmoothl1, self).__init__(size_average, reduce, reduction)\n",
    "        \n",
    "    def forward(self, observed, predicted, mask):\n",
    "        predicted_masked = mask*predicted\n",
    "        loss = F.smooth_l1_loss(observed, predicted_masked, reduction=self.reduction)\n",
    "        avg_loss = torch.sum(loss)/torch.sum(mask)\n",
    "        return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class modsmoothl1(nn.SmoothL1Loss):\n",
    "    def __init__(self, size_average=None, reduce=None, reduction = 'none'):\n",
    "        super(modsmoothl1, self).__init__(size_average, reduce, reduction)\n",
    "        \n",
    "    def forward(self, observed, predicted, mask):\n",
    "        predicted_masked = mask*predicted\n",
    "        loss = F.smooth_l1_loss(observed, predicted_masked, reduction=self.reduction)\n",
    "        avg_loss = torch.sum(loss)/torch.sum(mask)\n",
    "        return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_model = Model(input_size,\n",
    "                       output_size,\n",
    "                       seq_len, \n",
    "                       dropout).cuda().float()\n",
    "\n",
    "criterion = modsmoothl1()\n",
    "optimizer = torch.optim.RMSprop(forecast_model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, filename=\"MLR Final model.pth.tar\"):\n",
    "    print(\"Saving checkpoint...\")\n",
    "    torch.save(state, filename)\n",
    "\n",
    "\n",
    "def load_checkpoint(checkpoint, model, optimizer):\n",
    "    print(\"Loading checkpoint...\")\n",
    "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "    optimizer.load_state_dict(checkpoint[\"optimizer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#model train\n",
    "if load_model == False:\n",
    "    all_train_loss = []\n",
    "    all_val_loss = []\n",
    "    total_iter = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        forecast_model.train()\n",
    "        epoch_total_loss = 0.0\n",
    "\n",
    "        for i, (X_data, y_data, y_mask, index) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            X_data = X_data.cuda().float()\n",
    "            y_data = y_data.cuda().float()\n",
    "            y_mask = y_mask.cuda().float()        \n",
    "\n",
    "            y_pred = forecast_model(X_data.view(batch_size, input_size*seq_len))\n",
    "            loss = criterion(y_data, y_pred, y_mask)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_total_loss = epoch_total_loss + loss.item()\n",
    "\n",
    "        epoch_avg_loss = epoch_total_loss/len(train_loader)    \n",
    "        if (epoch +1) % round(num_epochs/10) == 0:\n",
    "            print (f'Train loss after Epoch [{epoch+1}/{num_epochs}]: {epoch_avg_loss:.6f}')\n",
    "\n",
    "        all_train_loss.append(epoch_avg_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving test and validation losses\n",
    "if load_model == False:\n",
    "    print(\"Saving losses...\")\n",
    "    df_train_loss = pd.DataFrame(all_train_loss, columns = [\"Values\"])\n",
    "    df_train_loss.to_csv('train_loss.csv', index = False)\n",
    "\n",
    "    df_val_loss = pd.DataFrame(all_val_loss, columns = [\"Values\"])\n",
    "    df_val_loss.to_csv('Validation_loss.csv', index = False)\n",
    "    \n",
    "    checkpoint = {\"state_dict\": forecast_model.state_dict(), \"optimizer\": optimizer.state_dict()}\n",
    "    save_checkpoint(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(list(range(1, num_epochs + 1)), all_train_loss, label = 'Train')\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.xlabel('No. of epochs')\n",
    "plt.ylabel('Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import winsound\n",
    "frequency = 2000  # Set Frequency To 2500 Hertz\n",
    "duration = 100  # Set Duration To 1000 ms == 1 second\n",
    "winsound.Beep(frequency, duration)\n",
    "winsound.Beep(frequency, duration)\n",
    "winsound.Beep(frequency, duration)\n",
    "winsound.Beep(frequency, duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_index = torch.empty(0).cuda()\n",
    "all_obs = torch.empty(0, output_size).cuda()\n",
    "all_pred = torch.empty(0, output_size).cuda()\n",
    "with torch.no_grad():\n",
    "    total_test_loss = 0.0\n",
    "    for i, (X_test, y_test, y_mask_test, index) in enumerate(test_loader):\n",
    "        X_test = X_test.cuda().float()\n",
    "        y_test = y_test.cuda().float()\n",
    "        y_mask_test = y_mask_test.cuda().float()\n",
    "        index = index.cuda().float()\n",
    "        \n",
    "        test_pred = forecast_model(X_test.view(batch_size, input_size*seq_len))\n",
    "        test_loss = criterion(y_test, test_pred, y_mask_test)\n",
    "        total_test_loss = total_test_loss + test_loss.item()\n",
    "        \n",
    "        all_index = torch.cat((all_index, index),0)\n",
    "        all_obs = torch.cat((all_obs, y_test), 0)\n",
    "        all_pred = torch.cat((all_pred, test_pred), 0)\n",
    "        \n",
    "        \n",
    "    avg_test_loss = total_test_loss/len(test_loader)\n",
    "    print(avg_test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_out_np = all_pred.cpu().numpy()\n",
    "obs_out_np = all_obs.cpu().numpy()\n",
    "df_out_mean = df_np_mean[7:13]\n",
    "df_out_std = df_np_std[7:13]\n",
    "final_pred = pred_out_np * df_out_std + df_out_mean\n",
    "final_observed = obs_out_np * df_out_std + df_out_mean\n",
    "all_index = all_index.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_obs_data = pd.DataFrame({'SO2  ': final_observed[:, 0],\n",
    "                         'NO2': final_observed[:, 1],\n",
    "                         'CO': final_observed[:, 2],\n",
    "                         'O3': final_observed[:, 3],\n",
    "                         'PM2.5': final_observed[:, 4], \n",
    "                         'PM10': final_observed[:, 5],\n",
    "                         'Index': all_index})\n",
    "filename_obs = 'MLR plot_obs.xlsx'\n",
    "out_obs_data.to_excel(filename_obs, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_pred_data = pd.DataFrame({'SO2  ': final_pred[:, 0],\n",
    "                         'NO2': final_pred[:, 1],\n",
    "                         'CO': final_pred[:, 2],\n",
    "                         'O3': final_pred[:, 3],\n",
    "                         'PM2.5': final_pred[:, 4], \n",
    "                         'PM10': final_pred[:, 5],\n",
    "                         'Index': all_index})\n",
    "filename_pred = 'MLR plot_pred.xlsx'\n",
    "out_pred_data.to_excel(filename_pred, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
